{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "\n",
    "# Set AWS region and feature store parameters\n",
    "AWS_REGION = \"us-east-2\"\n",
    "ATHENA_BUCKET = \"historical-cust-features-0602\" \n",
    "FEATURESTORE_BUCKET = \"customer-feature-store-0602\"  \n",
    "FEATURE_GROUP_NAME = \"CustomerTransactions\"\n",
    "ATHENA_DATABASE = \"featurestore_offline\"\n",
    "ATHENA_TABLE = \"CustomerTransactions\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Athena query started (QueryExecutionId: 3e6d0ce4-6ea4-4fd4-bc45-23544dac0c06)\n",
      "‚è≥ Query is still running...\n",
      "‚úÖ Query completed. Results stored at: s3://historical-cust-features-0602/3e6d0ce4-6ea4-4fd4-bc45-23544dac0c06.csv\n",
      "‚úÖ Results downloaded as 'historical_features.csv'\n",
      "‚úÖ Loaded 207 historical feature records into Pandas DataFrame.\n",
      "‚úÖ Model trained! Mean Squared Error: 9.27442504642858\n",
      "‚úÖ Model uploaded to S3: s3://customer-feature-store-0602/saved_models/model.pkl\n",
      "üéØ Model training and saving completed!\n"
     ]
    }
   ],
   "source": [
    "# Initialize AWS clients\n",
    "s3_client = boto3.client(\"s3\", region_name=AWS_REGION)\n",
    "athena_client = boto3.client(\"athena\", region_name=AWS_REGION)\n",
    "sagemaker_client = boto3.client(\"sagemaker\", region_name=AWS_REGION)\n",
    "\n",
    "# 1Ô∏è‚É£ RUN ATHENA QUERY TO FETCH HISTORICAL DATA\n",
    "def run_athena_query():\n",
    "    query = f\"\"\"\n",
    "    SELECT customer_id, event_time, latest_purchase_value, latest_loyalty_score\n",
    "    FROM {ATHENA_DATABASE}.{ATHENA_TABLE}\n",
    "    WHERE event_time BETWEEN '2022-01-01T00:00:00Z' AND '2022-08-31T23:59:59Z';\n",
    "    \"\"\"\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\"Database\": ATHENA_DATABASE},\n",
    "        ResultConfiguration={\"OutputLocation\": f\"s3://{ATHENA_BUCKET}/\"},\n",
    "    )\n",
    "    query_execution_id = response[\"QueryExecutionId\"]\n",
    "    print(f\"‚úÖ Athena query started (QueryExecutionId: {query_execution_id})\")\n",
    "    return query_execution_id\n",
    "\n",
    "# 2Ô∏è‚É£ WAIT FOR QUERY EXECUTION TO COMPLETE\n",
    "def wait_for_query(query_execution_id):\n",
    "    while True:\n",
    "        response = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "        state = response[\"QueryExecution\"][\"Status\"][\"State\"]\n",
    "        if state in [\"SUCCEEDED\", \"FAILED\", \"CANCELLED\"]:\n",
    "            break\n",
    "        print(\"‚è≥ Query is still running...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "    if state == \"SUCCEEDED\":\n",
    "        output_location = response[\"QueryExecution\"][\"ResultConfiguration\"][\"OutputLocation\"]\n",
    "        print(f\"‚úÖ Query completed. Results stored at: {output_location}\")\n",
    "        return output_location\n",
    "    else:\n",
    "        raise Exception(f\"‚ùå Query failed: {response['QueryExecution']['Status']['StateChangeReason']}\")\n",
    "\n",
    "# 3Ô∏è‚É£ DOWNLOAD QUERY RESULTS FROM S3\n",
    "def download_and_load_results(output_location):\n",
    "    filename = \"historical_features.csv\"\n",
    "    s3_client.download_file(ATHENA_BUCKET, output_location.split(\"/\")[-1], filename)\n",
    "    print(f\"‚úÖ Results downloaded as '{filename}'\")\n",
    "\n",
    "    # Load into Pandas\n",
    "    df = pd.read_csv(filename)\n",
    "    df[\"event_time\"] = pd.to_datetime(df[\"event_time\"])\n",
    "    df = df.sort_values(by=\"event_time\")\n",
    "    print(f\"‚úÖ Loaded {len(df)} historical feature records into Pandas DataFrame.\")\n",
    "    return df\n",
    "\n",
    "# 4Ô∏è‚É£ TRAIN ML MODEL\n",
    "def train_ml_model(df):\\\n",
    "  \n",
    "\n",
    "    # Select features and target variable\n",
    "    X = df[['latest_purchase_value']]\n",
    "    y = df['latest_loyalty_score']  \n",
    "\n",
    "    # Split into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a RandomForest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model performance\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"‚úÖ Model trained! Mean Squared Error: {mse}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# 5Ô∏è‚É£ SAVE MODEL TO S3\n",
    "def save_model(model):\n",
    "    model_filename = \"model.pkl\"\n",
    "    with open(model_filename, \"wb\") as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "\n",
    "    s3_key = \"saved_models/model.pkl\"\n",
    "    s3_client.upload_file(model_filename, FEATURESTORE_BUCKET, s3_key)\n",
    "    print(f\"‚úÖ Model uploaded to S3: s3://{FEATURESTORE_BUCKET}/{s3_key}\")\n",
    "\n",
    "# üü¢ EXECUTE ALL STEPS\n",
    "query_id = run_athena_query()\n",
    "query_output = wait_for_query(query_id)\n",
    "df_historical = download_and_load_results(query_output)\n",
    "ml_model = train_ml_model(df_historical)\n",
    "save_model(ml_model)\n",
    "\n",
    "print(\"üéØ Model training and saving completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
